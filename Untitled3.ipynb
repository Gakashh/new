{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRYOsau3YGubXoybtXkgyJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gakashh/new/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVP0f3GG7RN9",
        "outputId": "88e74b8a-a9e6-421d-f128-baa1f56a10f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (4.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9.9 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.9)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"JAVA_HOME = \", os.environ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIVMceV97bwf",
        "outputId": "b4f8f22a-a466-4352-dff7-a8d3bfdc1a8d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JAVA_HOME =  environ({'SHELL': '/bin/bash', 'NV_LIBCUBLAS_VERSION': '12.5.3.2-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'COLAB_JUPYTER_TRANSPORT': 'ipc', 'NV_NVML_DEV_VERSION': '12.5.82-1', 'NV_CUDNN_PACKAGE_NAME': 'libcudnn9-cuda-12', 'CGROUP_MEMORY_EVENTS': '/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events', 'NV_LIBNCCL_DEV_PACKAGE': 'libnccl-dev=2.22.3-1+cuda12.5', 'NV_LIBNCCL_DEV_PACKAGE_VERSION': '2.22.3-1', 'VM_GCE_METADATA_HOST': '169.254.169.253', 'MODEL_PROXY_HOST': 'https://mp.kaggle.net', 'HOSTNAME': 'ccaa3788e8cf', 'LANGUAGE': 'en_US', 'TBE_RUNTIME_ADDR': '172.28.0.1:8011', 'COLAB_TPU_1VM': '', 'GCE_METADATA_TIMEOUT': '3', 'NVIDIA_REQUIRE_CUDA': 'cuda>=12.5 brand=unknown,driver>=470,driver<471 brand=grid,driver>=470,driver<471 brand=tesla,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=vapps,driver>=470,driver<471 brand=vpc,driver>=470,driver<471 brand=vcs,driver>=470,driver<471 brand=vws,driver>=470,driver<471 brand=cloudgaming,driver>=470,driver<471 brand=unknown,driver>=535,driver<536 brand=grid,driver>=535,driver<536 brand=tesla,driver>=535,driver<536 brand=nvidia,driver>=535,driver<536 brand=quadro,driver>=535,driver<536 brand=quadrortx,driver>=535,driver<536 brand=nvidiartx,driver>=535,driver<536 brand=vapps,driver>=535,driver<536 brand=vpc,driver>=535,driver<536 brand=vcs,driver>=535,driver<536 brand=vws,driver>=535,driver<536 brand=cloudgaming,driver>=535,driver<536 brand=unknown,driver>=550,driver<551 brand=grid,driver>=550,driver<551 brand=tesla,driver>=550,driver<551 brand=nvidia,driver>=550,driver<551 brand=quadro,driver>=550,driver<551 brand=quadrortx,driver>=550,driver<551 brand=nvidiartx,driver>=550,driver<551 brand=vapps,driver>=550,driver<551 brand=vpc,driver>=550,driver<551 brand=vcs,driver>=550,driver<551 brand=vws,driver>=550,driver<551 brand=cloudgaming,driver>=550,driver<551', 'NV_LIBCUBLAS_DEV_PACKAGE': 'libcublas-dev-12-5=12.5.3.2-1', 'NV_NVTX_VERSION': '12.5.82-1', 'COLAB_JUPYTER_IP': '172.28.0.12', 'NV_CUDA_CUDART_DEV_VERSION': '12.5.82-1', 'NV_LIBCUSPARSE_VERSION': '12.5.1.3-1', 'COLAB_LANGUAGE_SERVER_PROXY_ROOT_URL': 'http://172.28.0.1:8013/', 'NV_LIBNPP_VERSION': '12.3.0.159-1', 'NCCL_VERSION': '2.22.3-1', 'KMP_LISTEN_PORT': '6000', 'TF_FORCE_GPU_ALLOW_GROWTH': 'true', 'ENV': '/root/.bashrc', 'PWD': '/', 'TBE_EPHEM_CREDS_ADDR': '172.28.0.1:8009', 'COLAB_LANGUAGE_SERVER_PROXY_REQUEST_TIMEOUT': '30s', 'TBE_CREDS_ADDR': '172.28.0.1:8008', 'NV_CUDNN_PACKAGE': 'libcudnn9-cuda-12=9.2.1.18-1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'COLAB_JUPYTER_TOKEN': '', 'LAST_FORCED_REBUILD': '20250623', 'NV_NVPROF_DEV_PACKAGE': 'cuda-nvprof-12-5=12.5.82-1', 'NV_LIBNPP_PACKAGE': 'libnpp-12-5=12.3.0.159-1', 'NV_LIBNCCL_DEV_PACKAGE_NAME': 'libnccl-dev', 'TCLLIBPATH': '/usr/share/tcltk/tcllib1.20', 'NV_LIBCUBLAS_DEV_VERSION': '12.5.3.2-1', 'NVIDIA_PRODUCT_NAME': 'CUDA', 'COLAB_KERNEL_MANAGER_PROXY_HOST': '172.28.0.12', 'UV_BUILD_CONSTRAINT': '', 'NV_LIBCUBLAS_DEV_PACKAGE_NAME': 'libcublas-dev-12-5', 'NV_CUDA_CUDART_VERSION': '12.5.82-1', 'COLAB_WARMUP_DEFAULTS': '1', 'HOME': '/root', 'LANG': 'en_US.UTF-8', 'CUDA_VERSION': '12.5.1', 'CLOUDSDK_CONFIG': '/content/.config', 'NV_LIBCUBLAS_PACKAGE': 'libcublas-12-5=12.5.3.2-1', 'NV_CUDA_NSIGHT_COMPUTE_DEV_PACKAGE': 'cuda-nsight-compute-12-5=12.5.1-1', 'UV_SYSTEM_PYTHON': 'true', 'COLAB_RELEASE_TAG': 'release-colab-external_20251208-060051_RC00', 'KMP_TARGET_PORT': '9000', 'KMP_EXTRA_ARGS': '--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https://colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/m-s-10bochzfnwbaw --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true ', 'UV_INSTALL_DIR': '/usr/local/bin', 'NV_LIBNPP_DEV_PACKAGE': 'libnpp-dev-12-5=12.3.0.159-1', 'COLAB_LANGUAGE_SERVER_PROXY_LSP_DIRS': '/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages', 'NV_LIBCUBLAS_PACKAGE_NAME': 'libcublas-12-5', 'COLAB_KERNEL_MANAGER_PROXY_PORT': '6000', 'CLOUDSDK_PYTHON': 'python3', 'NV_LIBNPP_DEV_VERSION': '12.3.0.159-1', 'NO_GCE_CHECK': 'False', 'PYTHONPATH': '/env/python', 'NV_LIBCUSPARSE_DEV_VERSION': '12.5.1.3-1', 'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs', 'NV_CUDNN_VERSION': '9.2.1.18-1', 'JAX_PLATFORMS': 'cpu', 'SHLVL': '0', 'NV_CUDA_LIB_VERSION': '12.5.1-1', 'COLAB_LANGUAGE_SERVER_PROXY': '/usr/colab/bin/language_service', 'NVARCH': 'x86_64', 'UV_CONSTRAINT': '', 'PYTHONUTF8': '1', 'NV_CUDNN_PACKAGE_DEV': 'libcudnn9-dev-cuda-12=9.2.1.18-1', 'JAX_SKIP_CUDA_CONSTRAINTS_CHECK': '1', 'NV_LIBNCCL_PACKAGE': 'libnccl2=2.22.3-1+cuda12.5', 'LD_LIBRARY_PATH': '/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'COLAB_GPU': '', 'NV_CUDA_NSIGHT_COMPUTE_VERSION': '12.5.1-1', 'GCS_READ_CACHE_BLOCK_SIZE_MB': '16', 'NV_NVPROF_VERSION': '12.5.82-1', 'LC_ALL': 'en_US.UTF-8', 'COLAB_FILE_HANDLER_ADDR': 'localhost:3453', 'PATH': '/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin', 'NV_LIBNCCL_PACKAGE_NAME': 'libnccl2', 'COLAB_DEBUG_ADAPTER_MUX_PATH': '/usr/local/bin/dap_multiplexer', 'NV_LIBNCCL_PACKAGE_VERSION': '2.22.3-1', 'PYTHONWARNINGS': 'ignore:::pip._internal.cli.base_command', 'DEBIAN_FRONTEND': 'noninteractive', 'COLAB_BACKEND_VERSION': 'next', 'OLDPWD': '/', '_PYVIZ_COMMS_INSTALLED': '1', 'PYDEVD_USE_FRAME_EVAL': 'NO', 'JPY_SESSION_NAME': 'https://github.com/Gakashh/new/blob/main/Untitled3.ipynb', 'JPY_PARENT_PID': '96', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://matplotlib_inline.backend_inline', 'ENABLE_DIRECTORYPREFETCHER': '1', 'USE_AUTH_EPHEM': '1', 'COLAB_NOTEBOOK_ID': 'https://github.com/Gakashh/new/blob/main/Untitled3.ipynb'})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "w3stdInN78hv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PySpark-Get-Started\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "svUuj-HG70Yw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"Alice\", 25), (\"Bob\", 30), (\"Charlie\", 35)]\n",
        "df = spark.createDataFrame(data, [\"Name\", \"Age\"])\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVWFbI3F8E79",
        "outputId": "707cc07b-6a30-4b44-8e4a-8941d87bf298"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+\n",
            "|   Name|Age|\n",
            "+-------+---+\n",
            "|  Alice| 25|\n",
            "|    Bob| 30|\n",
            "|Charlie| 35|\n",
            "+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practical 2"
      ],
      "metadata": {
        "id": "HvzqiNTspBxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"RDD_Example\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "# Create an RDD\n",
        "rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "\n",
        "# Map: Multiply each value by 10\n",
        "mapped_rdd = rdd.map(lambda x: x*10)\n",
        "print(\"Mapped :\", mapped_rdd.collect())\n",
        "\n",
        "# Filter: Keep even numbers (Divisible by 20)\n",
        "filtered_rdd = mapped_rdd.filter(lambda x: x % 20 == 0)\n",
        "print(\"Filtered :\", filtered_rdd.collect())\n",
        "\n",
        "# Flatmap: Split sentences into words\n",
        "sentences = sc.parallelize([\"Spark is fast\",\"RDD is powerful\"])\n",
        "words_rdd = sentences.flatMap(lambda line: line.split(\" \"))\n",
        "print(\"Flatmap Words (str.split) :\", words_rdd.collect())\n",
        "\n",
        "words_rdd1 = sentences.flatMap(lambda line: list(line))\n",
        "print(\"Flatmap Words (list) :\", words_rdd1.collect())\n",
        "\n",
        "import re\n",
        "words_rdd2 = sentences.flatMap(lambda line: re.split(\"a\", line))\n",
        "print(\"Flatmap Words (re.split) :\", words_rdd2.collect())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCZkzlqKozXA",
        "outputId": "ffc74e26-7b42-41b0-b41e-b6c9466dc72b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped : [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
            "Filtered : [20, 40, 60, 80, 100]\n",
            "Flatmap Words (str.split) : ['Spark', 'is', 'fast', 'RDD', 'is', 'powerful']\n",
            "Flatmap Words (list) : ['S', 'p', 'a', 'r', 'k', ' ', 'i', 's', ' ', 'f', 'a', 's', 't', 'R', 'D', 'D', ' ', 'i', 's', ' ', 'p', 'o', 'w', 'e', 'r', 'f', 'u', 'l']\n",
            "Flatmap Words (re.split) : ['Sp', 'rk is f', 'st', 'RDD is powerful']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practical 3"
      ],
      "metadata": {
        "id": "4D6tGMBIpXeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# SparkSession is the entry point to use DataFrame functionality\n",
        "spark = SparkSession.builder.appName(\"DataFrameSQL\").getOrCreate()\n",
        "\n",
        "#1. Create a sample RDD of tuples (name, age)\n",
        "people_rdd = spark.sparkContext.parallelize([(\"Alice\", 25), (\"Bob\", 30), (\"Charlie\", 25),(\"David\", 40)])\n",
        "\n",
        "#2. Convert the RDD to a DataFrame\n",
        "people_df = people_rdd.toDF([\"Name\", \"Age\"])\n",
        "people_df.printSchema()\n",
        "print(\"\\n--- SQL DataFrame\")\n",
        "people_df.show()\n",
        "\n",
        "#3. Register the DataFrame as a temporary SQL view\n",
        "people_df.createOrReplaceTempView(\"people\")\n",
        "\n",
        "#4. Run SQL queries on the view using spark.sql\n",
        "print(\"\\n--- SQL Query: Select people younger than 35 ---\")\n",
        "sql_query_result = spark.sql(\"SELECT * FROM people WHERE Age < 35 ORDER BY Age DESC\")\n",
        "sql_query_result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZe2gb1WpXQf",
        "outputId": "236225e3-de4b-407e-c13d-0611467b0995"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: long (nullable = true)\n",
            "\n",
            "\n",
            "--- SQL DataFrame\n",
            "+-------+---+\n",
            "|   Name|Age|\n",
            "+-------+---+\n",
            "|  Alice| 25|\n",
            "|    Bob| 30|\n",
            "|Charlie| 25|\n",
            "|  David| 40|\n",
            "+-------+---+\n",
            "\n",
            "\n",
            "--- SQL Query: Select people younger than 35 ---\n",
            "+-------+---+\n",
            "|   Name|Age|\n",
            "+-------+---+\n",
            "|    Bob| 30|\n",
            "|Charlie| 25|\n",
            "|  Alice| 25|\n",
            "+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, sum\n",
        "\n",
        "spark = SparkSession.builder.appName(\"CSVReader\").getOrCreate()\n",
        "\n",
        "tips_df = spark.read.csv(\"/content/tips.csv\", header=True, inferSchema=True)\n",
        "\n",
        "tips_df.show(30)\n",
        "tips_df.printSchema()\n",
        "tips_df.count()\n",
        "tips_df.describe().show()\n",
        "tips_df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in tips_df.columns]).show()\n",
        "tips_df.select(\"day\").distinct().show()\n",
        "tips_df.select(\"sex\").distinct().show()\n",
        "tips_df.groupBy(\"day\").avg(\"tip\").show()\n",
        "tips_df = tips_df.withColumn(\"tip_percent\", (col(\"tip\") / col(\"total_bill\")) * 100)\n",
        "tips_df.show(30)\n",
        "tips_df.groupBy(\"sex\").avg(\"tip_percent\").show()\n",
        "tips_df.stat.corr(\"total_bill\", \"tip\")\n",
        "tips_df.stat.corr(\"total_bill\", \"tip_percent\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "9vtQ1X9SwOny",
        "outputId": "5d2fdc5d-a875-4c94-9f7e-f50496d3add9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[PATH_NOT_FOUND] Path does not exist: file:/content/tips.csv. SQLSTATE: 42K03",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3402582852.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CSVReader\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtips_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/tips.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtips_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_remote_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/content/tips.csv. SQLSTATE: 42K03"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import os\n",
        "\n",
        "# Check if the file exists and print its content for diagnosis\n",
        "file_path = \"stud.json\"\n",
        "if os.path.exists(file_path):\n",
        "    print(f\"Content of {file_path}:\")\n",
        "    with open(file_path, 'r') as f:\n",
        "        print(f.read())\n",
        "else:\n",
        "    print(f\"File '{file_path}' not found.\")\n",
        "\n",
        "\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"ReadJSONExample\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Read JSON file with multiLine option\n",
        "df = spark.read.option(\"multiLine\", \"true\").json(file_path)\n",
        "\n",
        "# Show DataFrame\n",
        "df.show()\n",
        "\n",
        "# Print schema\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAoSpWszpgbW",
        "outputId": "e36d5fcd-80df-418e-a19e-3a4f1be17d90"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content of stud.json:\n",
            "[\n",
            "  {\n",
            "    \"id\": 1,\n",
            "    \"name\": \"Alice\",\n",
            "    \"age\": 25,\n",
            "    \"city\": \"New York\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": 2,\n",
            "    \"name\": \"Bob\",\n",
            "    \"age\": 30,\n",
            "    \"city\": \"Los Angeles\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": 3,\n",
            "    \"name\": \"Charlie\",\n",
            "    \"age\": 28,\n",
            "    \"city\": \"Chicago\"\n",
            "  }\n",
            "]\n",
            "\n",
            "\n",
            "\n",
            "+---+-----------+---+-------+\n",
            "|age|       city| id|   name|\n",
            "+---+-----------+---+-------+\n",
            "| 25|   New York|  1|  Alice|\n",
            "| 30|Los Angeles|  2|    Bob|\n",
            "| 28|    Chicago|  3|Charlie|\n",
            "+---+-----------+---+-------+\n",
            "\n",
            "root\n",
            " |-- age: long (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bOx51BPsu67E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dask[complete]\n",
        "!pip install dask[distributed]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg2_KsEFwwdZ",
        "outputId": "146b5fc9-9e72-4823-e412-c31db5a53a02"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dask[complete] in /usr/local/lib/python3.12/dist-packages (2025.9.1)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (8.3.1)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (3.1.2)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (25.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (6.0.3)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (0.12.1)\n",
            "Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (18.1.0)\n",
            "Collecting lz4>=4.3.2 (from dask[complete])\n",
            "  Downloading lz4-4.4.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.12/dist-packages (from partd>=1.4.0->dask[complete]) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (2.2.2)\n",
            "Requirement already satisfied: distributed==2025.9.1 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (2025.9.1)\n",
            "Requirement already satisfied: bokeh>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (3.7.3)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (3.1.6)\n",
            "Requirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[complete]) (1.1.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[complete]) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[complete]) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[complete]) (3.2.2)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[complete]) (6.5.1)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[complete]) (2.5.0)\n",
            "Requirement already satisfied: zict>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[complete]) (3.0.0)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.12/dist-packages (from bokeh>=3.1.0->dask[complete]) (1.3.3)\n",
            "Requirement already satisfied: narwhals>=1.13 in /usr/local/lib/python3.12/dist-packages (from bokeh>=3.1.0->dask[complete]) (2.13.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from bokeh>=3.1.0->dask[complete]) (11.3.0)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.12/dist-packages (from bokeh>=3.1.0->dask[complete]) (2025.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=2.10.3->dask[complete]) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0->dask[complete]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0->dask[complete]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0->dask[complete]) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[complete]) (1.17.0)\n",
            "Downloading lz4-4.4.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lz4\n",
            "Successfully installed lz4-4.4.5\n",
            "Requirement already satisfied: dask[distributed] in /usr/local/lib/python3.12/dist-packages (2025.9.1)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.12/dist-packages (from dask[distributed]) (8.3.1)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from dask[distributed]) (3.1.2)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.12/dist-packages (from dask[distributed]) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from dask[distributed]) (25.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from dask[distributed]) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from dask[distributed]) (6.0.3)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from dask[distributed]) (0.12.1)\n",
            "Requirement already satisfied: distributed==2025.9.1 in /usr/local/lib/python3.12/dist-packages (from dask[distributed]) (2025.9.1)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[distributed]) (3.1.6)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[distributed]) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[distributed]) (1.1.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[distributed]) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[distributed]) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[distributed]) (3.2.2)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[distributed]) (6.5.1)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[distributed]) (2.5.0)\n",
            "Requirement already satisfied: zict>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[distributed]) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=2.10.3->distributed==2025.9.1->dask[distributed]) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dask.distributed import Client\n",
        "\n",
        "client = Client()\n",
        "print(client)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB1zg23vxQWo",
        "outputId": "1ade0794-a9e2-41cb-f279-aa9dd7e7a2fb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/distributed/node.py:187: UserWarning: Port 8787 is already in use.\n",
            "Perhaps you already have a cluster running?\n",
            "Hosting the HTTP server on port 39147 instead\n",
            "  warnings.warn(\n",
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:40511\n",
            "INFO:distributed.scheduler:  dashboard at:  http://127.0.0.1:39147/status\n",
            "INFO:distributed.scheduler:Registering Worker plugin shuffle\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:38685'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:42167'\n",
            "INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:38137 name: 0\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:38137\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:34230\n",
            "INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:38139 name: 1\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:38139\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:34240\n",
            "INFO:distributed.scheduler:Receive client connection: Client-d49918cd-d58a-11f0-8157-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:34254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Client: 'tcp://127.0.0.1:40511' processes=2 threads=2, memory=12.67 GiB>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Du9hRD-Xx7g6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}